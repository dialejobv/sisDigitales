<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Hand Detection</title>

  <!-- Import MediaPipe and Drawing Utilities -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>

  <!-- Minimal CSS to center video and canvas -->
  <style>
    body { display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; }
    video, canvas { position: absolute; transform: rotateY(180deg); } /* Mirror video and canvas */
  </style>
</head>
<body>

  <!-- Video and Canvas Elements for Real-Time Detection -->
  <video id="webcam" autoplay playsinline></video>
  <canvas id="output_canvas"></canvas>

  <!-- Main JavaScript for Hand Landmark Detection -->
  <script type="module">
    import { HandLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    let handLandmarker;          // Hand landmark detection instance
    let runningMode = "VIDEO";    // Set running mode to video for real-time detection
    let lastVideoTime = -1;       // Track video frame timing

    // Initialize hand landmark detector
    const initializeHandLandmarker = async () => {
      const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
      handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "GPU"
        },
        runningMode: runningMode,
        numHands: 2
      });
    };
    initializeHandLandmarker(); // Initialize landmarker

    const video = document.getElementById("webcam");           // Webcam video element
    const canvas = document.getElementById("output_canvas");   // Canvas for drawing landmarks
    const canvasCtx = canvas.getContext("2d");

    // Enable webcam and set up real-time detection
    if (navigator.mediaDevices?.getUserMedia) {
      navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
        video.srcObject = stream;
        video.addEventListener("loadeddata", predictWebcam);
      });
    }

    // Predict landmarks on each video frame
    async function predictWebcam() {
      if (handLandmarker && video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;

        // Set canvas dimensions to match video
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Detect hand landmarks in the current video frame
        const results = await handLandmarker.detectForVideo(video, performance.now());

        // Clear previous drawings
        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

        // Draw detected landmarks and connections
        if (results.landmarks) {
          for (const landmarks of results.landmarks) {
            drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { color: "#00FF00", lineWidth: 5 });
            drawLandmarks(canvasCtx, landmarks, { color: "#FF0000", lineWidth: 2 });
          }
        }
      }
      requestAnimationFrame(predictWebcam); // Continue detecting on the next frame
    }
  </script>
</body>
</html>